{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import xgboost, lightgbm\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Prog_files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\Prog_files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_txt = pd.read_csv(\"training_text\",sep='\\|\\|', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "test_txt = pd.read_csv(\"test_text\",sep='\\|\\|', header=None, names=[\"ID\",\"Text\"])\n",
    "train_var = pd.read_csv(\"training_variants\",sep=',')\n",
    "test_var = pd.read_csv(\"test_variants\",sep=',',header=None,names=['ID', 'Gene', 'Variation', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_txt (3321, 2)\n",
      "test_txt (368, 2)\n",
      "train_var (3321, 4)\n",
      "test_var (368, 4)\n"
     ]
    }
   ],
   "source": [
    "print('train_txt',train_txt.shape)\n",
    "print('test_txt',test_txt.shape)\n",
    "print('train_var',train_var.shape)\n",
    "print('test_var',test_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  \\\n",
       "0   0  FAM58A  Truncating Mutations   \n",
       "1   1     CBL                 W802*   \n",
       "2   2     CBL                 Q249E   \n",
       "3   3     CBL                 N454D   \n",
       "4   4     CBL                 L399V   \n",
       "\n",
       "                                                Text  Class  \n",
       "0  Cyclin-dependent kinases (CDKs) regulate a var...      1  \n",
       "1   Abstract Background  Non-small cell lung canc...      2  \n",
       "2   Abstract Background  Non-small cell lung canc...      2  \n",
       "3  Recent evidence has demonstrated that acquired...      3  \n",
       "4  Oncogenic mutations in the monomeric Casitas B...      4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.merge(train_var,train_txt,how='inner',on='ID')\n",
    "train_set = train_set[['ID', 'Gene', 'Variation', 'Text', 'Class']]\n",
    "train_set.dropna(inplace=True)\n",
    "train_set.reset_index(inplace=True)\n",
    "# train_set.drop(columns=['ID','index'],axis=1,inplace=True)\n",
    "train_set.drop(columns=['index'],axis=1,inplace=True)\n",
    "print(train_set.shape)\n",
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CBL</td>\n",
       "      <td>H398Q</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>S80N</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SHOC2</td>\n",
       "      <td>M173I</td>\n",
       "      <td>Rasopathies are phenotypically similar syndrom...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DICER1</td>\n",
       "      <td>D1709N</td>\n",
       "      <td>Abstract  DICER1 plays a critical role in mic...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PTPRT</td>\n",
       "      <td>S492F</td>\n",
       "      <td>The receptor protein tyrosine phosphatase T (P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene Variation                                               Text  \\\n",
       "0   0     CBL     H398Q  Oncogenic mutations in the monomeric Casitas B...   \n",
       "1   1     CBL      S80N   Abstract Background  Non-small cell lung canc...   \n",
       "2   2   SHOC2     M173I  Rasopathies are phenotypically similar syndrom...   \n",
       "3   3  DICER1    D1709N   Abstract  DICER1 plays a critical role in mic...   \n",
       "4   4   PTPRT     S492F  The receptor protein tyrosine phosphatase T (P...   \n",
       "\n",
       "   Class  \n",
       "0      4  \n",
       "1      6  \n",
       "2      4  \n",
       "3      4  \n",
       "4      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.merge(test_var,test_txt,how='inner',on='ID')\n",
    "test_set = test_set[['ID', 'Gene', 'Variation', 'Text', 'Class']]\n",
    "test_set.dropna(inplace=True)\n",
    "test_set.reset_index(inplace=True)\n",
    "# test_set.drop(columns=['ID','index'],axis=1,inplace=True)\n",
    "test_set.drop(columns=['index'],axis=1,inplace=True)\n",
    "print(test_set.shape)\n",
    "test_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set.describe(include = 'all')\n",
    "# test_set.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_train_gene = 262\n",
      "count_test_gene = 139\n"
     ]
    }
   ],
   "source": [
    "train_gene = train_set['Gene'].unique()\n",
    "print('count_train_gene =',len(train_gene))\n",
    "test_gene = test_set['Gene'].unique()\n",
    "print('count_test_gene =',len(test_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_train_variation = 2993\n",
      "count_test_variation = 328\n"
     ]
    }
   ],
   "source": [
    "train_variation = train_set['Variation'].unique()\n",
    "print('count_train_variation =',len(train_variation))\n",
    "test_variation = test_set['Variation'].unique()\n",
    "print('count_test_variation =',len(test_variation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_info(text):\n",
    "    txt_split = re.split('[0-9]*',text)\n",
    "    txt_split = [i for i in txt_split if i != '']\n",
    "    if len(txt_split) == 0: first_char, second_char, third_char = '','',''\n",
    "    elif len(txt_split) == 1: first_char, second_char, third_char = txt_split[0],'',''\n",
    "    elif len(txt_split) == 2: first_char, second_char, third_char = txt_split[0],txt_split[1],''\n",
    "    elif len(txt_split) == 3: first_char, second_char, third_char = txt_split[0],txt_split[1],txt_split[2]\n",
    "    return first_char, second_char, third_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_info(text):\n",
    "    txt_split = re.split('[A-Z]*',text)\n",
    "    txt_split = [i for i in txt_split if i != '']\n",
    "    if len(txt_split) == 0: first_num, second_num, third_num = 0,0,0\n",
    "    elif len(txt_split) == 1: first_num, second_num, third_num = int(txt_split[0]),0,0\n",
    "    elif len(txt_split) == 2: first_num, second_num, third_num = int(txt_split[0]),int(txt_split[1]),0\n",
    "    elif len(txt_split) == 3: first_num, second_num, third_num = int(txt_split[0]),int(txt_split[1]),int(txt_split[2])\n",
    "    return first_num, second_num, third_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_features(gene):\n",
    "    first_char, second_char, third_char = get_char_info(gene)\n",
    "    first_num, second_num, third_num = get_num_info(gene)\n",
    "    len_char1 = len(first_char)\n",
    "    len_char2 = len(second_char)\n",
    "    len_char3 = len(third_char)\n",
    "    if len_char1 > 0 : gene_char1 = first_char[0]\n",
    "    else: gene_char1 = ' '\n",
    "    if len_char2 > 0 : gene_char2 = second_char[0]\n",
    "    else: gene_char2 = ' '\n",
    "    if len_char3 > 0 : gene_char3 = third_char[0]\n",
    "    else: gene_char3 = ' '\n",
    "    return gene_char1, len_char1, gene_char2, len_char2, gene_char3, len_char3, first_num, second_num, third_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pure numbers\n",
    "def extract_num_frm_text(text):\n",
    "    m = re.search(' [0-9]* ',text)\n",
    "    if m is not None:\n",
    "        number = int(m.group())\n",
    "        sp = text.split(m.group())\n",
    "        other = ' '.join(sp)\n",
    "    else:\n",
    "        number = 0\n",
    "        other = text\n",
    "    return number, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only text \n",
    "def extract_pure_text_frm_text(text):\n",
    "    txt_splits = re.split(' ',text)\n",
    "    pure,non_pure = [],[]\n",
    "    for txt in txt_splits:\n",
    "        m = re.search('[A-Z][a-z]*|[a-z/]*',txt)\n",
    "        if m is not None and m.group() == txt:\n",
    "            pure.append(txt)\n",
    "        else: non_pure.append(txt)\n",
    "    pure_text = ' '.join(pure)\n",
    "    non_pure_text = ''.join(non_pure)\n",
    "    return pure_text,non_pure_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category_combination_from_text(text):\n",
    "    rep = re.sub('\\_|\\?|\\'|\\*|\\-','',text)\n",
    "    cat = ''.join(re.split('[A-Z0-9]*',rep))\n",
    "    comb = ''.join(re.split('[a-z]*',rep))\n",
    "    return cat,comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_and_variations_features(df):\n",
    "    for i in range(len(df)):\n",
    "        variation = df.loc[i,'Variation']\n",
    "        gene = train_set.loc[i,'Gene']\n",
    "        number, other = extract_num_frm_text(variation)\n",
    "        pure_text, non_pure_text = extract_pure_text_frm_text(other)\n",
    "        cat, comb = extract_category_combination_from_text(non_pure_text)\n",
    "        v_char1,v_len1,v_char2,v_len2,v_char3,v_len3,v_num1,v_num2,v_num3 = gene_features(comb)\n",
    "        gene = re.sub('\\_|\\?|\\'|\\*|\\-','',gene)\n",
    "        g_char1,g_len1,g_char2,g_len2,g_char3,g_len3,g_num1,g_num2,g_num3 = gene_features(gene)\n",
    "        df.loc[i,'var_number'] = number\n",
    "        df.loc[i,'var_pure_text'] = pure_text\n",
    "        df.loc[i,'var_category'] = cat\n",
    "        df.loc[i,'var_combination'] = comb\n",
    "        df.loc[i,'var_comb_char1'] = v_char1\n",
    "        df.loc[i,'var_comb_char1_len'] = v_len1\n",
    "        df.loc[i,'var_comb_char2'] = v_char2\n",
    "        df.loc[i,'var_comb_char2_len'] = v_len2\n",
    "        df.loc[i,'var_comb_char3'] = v_char3\n",
    "        df.loc[i,'var_comb_char3_len'] = v_len3\n",
    "        df.loc[i,'var_comb_num1'] = v_num1\n",
    "        df.loc[i,'var_comb_num2'] = v_num2\n",
    "        df.loc[i,'var_comb_num3'] = v_num3\n",
    "        df.loc[i,'gene_char1'] = g_char1\n",
    "        df.loc[i,'gene_char1_len'] = g_len1\n",
    "        df.loc[i,'gene_char2'] = g_char2\n",
    "        df.loc[i,'gene_char2_len'] = g_len2\n",
    "        df.loc[i,'gene_char3'] = g_char3\n",
    "        df.loc[i,'gene_char3_len'] = g_len3\n",
    "        df.loc[i,'gene_num1'] = g_num1\n",
    "        df.loc[i,'gene_num2'] = g_num2\n",
    "        df.loc[i,'gene_num3'] = g_num3\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316, 4)\n",
      "(367, 4)\n"
     ]
    }
   ],
   "source": [
    "train_set.drop(columns='Text',inplace=True)\n",
    "test_set.drop(columns='Text',inplace=True)\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Prog_files\\Anaconda3\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "train_set_mod = gene_and_variations_features(train_set)\n",
    "test_set_mod = gene_and_variations_features(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new = train_set_mod.drop(columns=['Gene', 'Variation','var_combination'])\n",
    "test_set_new = test_set_mod.drop(columns=['Gene', 'Variation', 'var_combination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Class', 'var_number', 'var_pure_text', 'var_category',\n",
       "       'var_comb_char1', 'var_comb_char1_len', 'var_comb_char2',\n",
       "       'var_comb_char2_len', 'var_comb_char3', 'var_comb_char3_len',\n",
       "       'var_comb_num1', 'var_comb_num2', 'var_comb_num3', 'gene_char1',\n",
       "       'gene_char1_len', 'gene_char2', 'gene_char2_len', 'gene_char3',\n",
       "       'gene_char3_len', 'gene_num1', 'gene_num2', 'gene_num3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316, 23)\n"
     ]
    }
   ],
   "source": [
    "# train_set_new.describe(include='all')\n",
    "cat_columns = ['var_category', 'var_comb_char1', 'var_comb_char2', 'var_comb_char3', \n",
    "               'gene_char1', 'gene_char2', 'gene_char3']\n",
    "print(train_set_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_category 13\n",
      "(3316, 36)\n",
      "(367, 36)\n",
      "var_comb_char1 24\n",
      "(3316, 60)\n",
      "(367, 60)\n",
      "var_comb_char2 25\n",
      "(3316, 85)\n",
      "(367, 85)\n",
      "var_comb_char3 21\n",
      "(3316, 106)\n",
      "(367, 106)\n",
      "gene_char1 23\n",
      "(3316, 129)\n",
      "(367, 129)\n",
      "gene_char2 11\n",
      "(3316, 140)\n",
      "(367, 140)\n",
      "gene_char3 3\n",
      "(3316, 143)\n",
      "(367, 143)\n"
     ]
    }
   ],
   "source": [
    "for col in cat_columns:\n",
    "    cat_features = train_set_new[col]\n",
    "    test_cat_features = train_set_new[col]\n",
    "    enc = LabelEncoder()\n",
    "    new_cat_features = enc.fit_transform(cat_features)\n",
    "    new_cat_features = new_cat_features.reshape(-1, 1) # Needs to be the correct shape\n",
    "    test_new_cat_features = enc.fit_transform(test_cat_features)\n",
    "    test_new_cat_features = test_new_cat_features.reshape(-1, 1) # Needs to be the correct shape\n",
    "    ohe = OneHotEncoder(sparse=False) #Easier to read\n",
    "    matrix = ohe.fit_transform(new_cat_features)\n",
    "    test_matrix = ohe.fit_transform(test_new_cat_features)\n",
    "    matrix_df = pd.DataFrame(matrix,columns = col+'_'+enc.classes_)\n",
    "    test_matrix_df = pd.DataFrame(test_matrix,columns = col+'_'+enc.classes_)\n",
    "    train_set_new = train_set_new.merge(matrix_df, how='inner',left_index=True, right_index=True)\n",
    "    test_set_new = test_set_new.merge(test_matrix_df, how='inner',left_index=True, right_index=True)\n",
    "    print(col,len(enc.classes_))\n",
    "    print(train_set_new.shape)\n",
    "    print(test_set_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316, 136)\n",
      "(367, 136)\n"
     ]
    }
   ],
   "source": [
    "train_set_new = train_set_new.drop(columns=cat_columns)\n",
    "test_set_new = test_set_new.drop(columns=cat_columns)\n",
    "print(train_set_new.shape)\n",
    "print(test_set_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new = pd.merge(train_set_new,train_txt,how='inner',on='ID')\n",
    "test_set_new = pd.merge(test_set_new,train_txt,how='inner',on='ID')\n",
    "# train_set_new.to_csv('mod_train.csv',index=False)\n",
    "# test_set_new.to_csv('mod_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316, 137)\n",
      "(367, 137)\n",
      "(3316, 136)\n",
      "(367, 136)\n"
     ]
    }
   ],
   "source": [
    "print(train_set_new.shape)\n",
    "print(test_set_new.shape)\n",
    "train_set_new.drop(columns='ID',inplace=True)\n",
    "test_set_new.drop(columns='ID',inplace=True)\n",
    "print(train_set_new.shape)\n",
    "print(test_set_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "newstopwords=stopwords.words(\"English\")\n",
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "\n",
    "def pre_process(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens=[WNlemma.lemmatize(t) for t in tokens]\n",
    "    tokens=[word for word in tokens if word not in newstopwords]\n",
    "    text_after_process=\" \".join(tokens)\n",
    "    return(text_after_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new['Text'] = train_set_new['Text'].apply(pre_process)\n",
    "test_set_new['Text'] = test_set_new['Text'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new['var_pure_text'] = train_set_new['var_pure_text'].apply(pre_process)\n",
    "test_set_new['var_pure_text'] = test_set_new['var_pure_text'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_x = [col for col in train_set_new.columns if col != 'Class']\n",
    "len(cols_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_set_new[cols_x], train_set_new.Class, \n",
    "                                                      test_size=0.2, random_state=12,\n",
    "                                                      stratify=train_set_new.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_xx = [col for col in train_set_new.columns if col not in  ['Class','Text','var_pure_text']]\n",
    "len(cols_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2652, 150158)\n",
      "(2652, 150158)\n",
      "(2652, 100)\n"
     ]
    }
   ],
   "source": [
    "# Text\n",
    "count_vect_text = CountVectorizer()\n",
    "X_train_counts = count_vect_text.fit_transform(X_train.Text)\n",
    "print(X_train_counts.shape)\n",
    "tfidf_transformer_text = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer_text.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "text_svd = TruncatedSVD(n_components=100, n_iter=25, random_state=12)\n",
    "X_train_tfidf_trun = text_svd.fit_transform(X_train_tfidf)\n",
    "print(X_train_tfidf_trun.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664, 150158)\n",
      "(664, 100)\n"
     ]
    }
   ],
   "source": [
    "X_valid_counts = count_vect_text.transform(X_valid.Text)\n",
    "X_valid_tfidf = tfidf_transformer_text.transform(X_valid_counts)\n",
    "print(X_valid_tfidf.shape)\n",
    "X_valid_tfidf_trun = text_svd.transform(X_valid_tfidf)\n",
    "print(X_valid_tfidf_trun.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2652, 26)\n",
      "(2652, 26)\n"
     ]
    }
   ],
   "source": [
    "# var_pure_text\n",
    "count_vect_var = CountVectorizer()\n",
    "X_var_train_counts = count_vect_var.fit_transform(X_train.var_pure_text)\n",
    "print(X_var_train_counts.shape)\n",
    "tfidf_transformer_var = TfidfTransformer()\n",
    "X_var_train_tfidf = tfidf_transformer_var.fit_transform(X_var_train_counts)\n",
    "print(X_var_train_tfidf.shape)\n",
    "# var_svd = TruncatedSVD(n_components=25, n_iter=25, random_state=12)\n",
    "# X_var_train_tfidf_trun = var_svd.fit_transform(X_var_train_tfidf)\n",
    "# print(X_var_train_tfidf_trun.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664, 26)\n"
     ]
    }
   ],
   "source": [
    "X_var_valid_counts = count_vect_var.transform(X_valid.var_pure_text)\n",
    "X_var_valid_tfidf = tfidf_transformer_var.transform(X_var_valid_counts)\n",
    "print(X_var_valid_tfidf.shape)\n",
    "# X_var_valid_tfidf_trun = var_svd.transform(X_var_valid_tfidf)\n",
    "# print(X_var_valid_tfidf_trun.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = hstack((np.array(X_train[cols_xx])\n",
    "                      ,X_var_train_tfidf\n",
    "#                       ,X_train_tfidf_trun\n",
    "                     ))\n",
    "X_valid_new = hstack((np.array(X_valid[cols_xx])\n",
    "                      ,X_var_valid_tfidf\n",
    "#                       ,X_valid_tfidf_trun\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664, 159)\n",
      "(2652, 159)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid_new.shape)\n",
    "print(X_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# clf = MultinomialNB().fit(X_train_new, y_train)\n",
    "# y_pred = clf.predict(X_valid_new)\n",
    "# print(metrics.confusion_matrix(y_valid, y_pred))\n",
    "# print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import tree\n",
    "# clf = tree.DecisionTreeClassifier().fit(X_train_new, y_train)\n",
    "# y_pred = clf.predict(X_valid_new)\n",
    "# print(metrics.confusion_matrix(y_valid, y_pred))\n",
    "# print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# from sklearn.svm import SVC\n",
    "# clf = svm.LinearSVC(C=1.0).fit(X_train_new, y_train)\n",
    "# y_pred = clf.predict(X_valid_new)\n",
    "# print(metrics.confusion_matrix(y_valid, y_pred))\n",
    "# print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5993975903614458\n",
      "1.870137088947707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=50, max_features=100, random_state=0)\n",
    "clf.fit(X_train_new, y_train)\n",
    "y_pred = clf.predict(X_valid_new)\n",
    "y_prob = clf.predict_proba(X_valid_new)\n",
    "print(accuracy_score(y_valid, y_pred))\n",
    "print(log_loss(y_valid, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# clf = GradientBoostingClassifier(n_estimators=300, max_depth=20, max_features=50, random_state=0)\n",
    "# clf.fit(X_train_new, y_train)\n",
    "# y_pred = clf.predict(X_valid_new)\n",
    "# print(metrics.confusion_matrix(y_valid, y_pred))\n",
    "# print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73   3   1  25   6   1   4   0   0]\n",
      " [  5  46   0   0   2   2  36   0   0]\n",
      " [  0   0   9   4   0   0   5   0   0]\n",
      " [ 20   1   2 101   5   1   7   0   0]\n",
      " [  6   2   2   1  25   3   9   0   0]\n",
      " [  3   1   0   6   2  34   9   0   0]\n",
      " [  2  14   2   5   0   1 167   0   0]\n",
      " [  0   0   0   1   0   0   3   0   0]\n",
      " [  0   0   0   1   0   0   3   0   3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.65      0.66       113\n",
      "          2       0.69      0.51      0.58        91\n",
      "          3       0.56      0.50      0.53        18\n",
      "          4       0.70      0.74      0.72       137\n",
      "          5       0.62      0.52      0.57        48\n",
      "          6       0.81      0.62      0.70        55\n",
      "          7       0.69      0.87      0.77       191\n",
      "          8       0.00      0.00      0.00         4\n",
      "          9       1.00      0.43      0.60         7\n",
      "\n",
      "avg / total       0.69      0.69      0.68       664\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Prog_files\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\Prog_files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(max_depth=8, min_child_weight=3, subsample=0.9, colsample_bytree=0.6, learning_rate=0.1, n_estimators=100, random_state=0)\n",
    "clf.fit(X_train_new, y_train)\n",
    "y_pred = clf.predict(X_valid_new)\n",
    "y_prob = clf.predict_proba(X_valid_new)\n",
    "print(accuracy_score(y_valid, y_pred))\n",
    "print(log_loss(y_valid, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 72   3   1  26   6   2   3   0   0]\n",
      " [  5  47   0   0   2   2  35   0   0]\n",
      " [  1   0   9   4   0   0   4   0   0]\n",
      " [ 18   0   3 103   4   0   9   0   0]\n",
      " [  8   3   2   2  20   5   8   0   0]\n",
      " [  6   2   0   5   0  35   7   0   0]\n",
      " [  2  16   3   3   0   2 165   0   0]\n",
      " [  0   0   0   1   0   0   3   0   0]\n",
      " [  0   0   0   2   0   0   1   0   4]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64       113\n",
      "          2       0.66      0.52      0.58        91\n",
      "          3       0.50      0.50      0.50        18\n",
      "          4       0.71      0.75      0.73       137\n",
      "          5       0.62      0.42      0.50        48\n",
      "          6       0.76      0.64      0.69        55\n",
      "          7       0.70      0.86      0.77       191\n",
      "          8       0.00      0.00      0.00         4\n",
      "          9       1.00      0.57      0.73         7\n",
      "\n",
      "avg / total       0.68      0.69      0.68       664\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Prog_files\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:452: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n",
      "D:\\Prog_files\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\Prog_files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMClassifier(max_depth=20, min_child_weight=3, subsample=0.9, colsample_bytree=0.6, learning_rate=0.1, n_estimators=200, random_state=0)\n",
    "clf.fit(X_train_new, y_train)\n",
    "y_pred = clf.predict(X_valid_new)\n",
    "y_prob = clf.predict_proba(X_valid_new)\n",
    "print(accuracy_score(y_valid, y_pred))\n",
    "print(log_loss(y_valid, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
